{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNI8Fe+x+weesNZM6JYDiA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergeyLimanskiy/Study/blob/main/%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81_%D0%B8%D0%B3%D1%80%D1%8B_%D0%B2_%D0%BA%D0%BE%D1%81%D1%82%D0%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0soVgADkIrE",
        "outputId": "94bed0d5-437a-42ed-9734-71b023514360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned Policy:\n",
            "Points: 26, Rolls Left: 17 => Action: ROLL\n",
            "Points: 15, Rolls Left: 18 => Action: ROLL\n",
            "Points: 4, Rolls Left: 19 => Action: ROLL\n",
            "Points: 0, Rolls Left: 20 => Action: ROLL\n",
            "Points: 28, Rolls Left: 16 => Action: ROLL\n",
            "Points: 21, Rolls Left: 17 => Action: ROLL\n",
            "Points: 12, Rolls Left: 18 => Action: ROLL\n",
            "Points: 5, Rolls Left: 19 => Action: ROLL\n",
            "Points: 26, Rolls Left: 16 => Action: ROLL\n",
            "Points: 19, Rolls Left: 17 => Action: ROLL\n",
            "Points: 14, Rolls Left: 18 => Action: ROLL\n",
            "Points: 6, Rolls Left: 19 => Action: ROLL\n",
            "Points: 29, Rolls Left: 16 => Action: ROLL\n",
            "Points: 23, Rolls Left: 17 => Action: ROLL\n",
            "Points: 13, Rolls Left: 18 => Action: ROLL\n",
            "Points: 26, Rolls Left: 15 => Action: ROLL\n",
            "Points: 18, Rolls Left: 16 => Action: ROLL\n",
            "Points: 15, Rolls Left: 17 => Action: ROLL\n",
            "Points: 9, Rolls Left: 18 => Action: ROLL\n",
            "Points: 18, Rolls Left: 17 => Action: ROLL\n",
            "Points: 11, Rolls Left: 18 => Action: ROLL\n",
            "Points: 8, Rolls Left: 19 => Action: ROLL\n",
            "Points: 25, Rolls Left: 16 => Action: ROLL\n",
            "Points: 19, Rolls Left: 18 => Action: ROLL\n",
            "Points: 11, Rolls Left: 19 => Action: ROLL\n",
            "Points: 27, Rolls Left: 15 => Action: ROLL\n",
            "Points: 23, Rolls Left: 16 => Action: ROLL\n",
            "Points: 17, Rolls Left: 17 => Action: ROLL\n",
            "Points: 6, Rolls Left: 18 => Action: ROLL\n",
            "Points: 3, Rolls Left: 19 => Action: ROLL\n",
            "Points: 27, Rolls Left: 17 => Action: ROLL\n",
            "Points: 18, Rolls Left: 18 => Action: ROLL\n",
            "Points: 14, Rolls Left: 17 => Action: ROLL\n",
            "Points: 7, Rolls Left: 19 => Action: ROLL\n",
            "Points: 25, Rolls Left: 15 => Action: ROLL\n",
            "Points: 21, Rolls Left: 16 => Action: ROLL\n",
            "Points: 16, Rolls Left: 17 => Action: ROLL\n",
            "Points: 9, Rolls Left: 19 => Action: ROLL\n",
            "Points: 20, Rolls Left: 17 => Action: ROLL\n",
            "Points: 24, Rolls Left: 16 => Action: ROLL\n",
            "Points: 28, Rolls Left: 15 => Action: ROLL\n",
            "Points: 28, Rolls Left: 14 => Action: ROLL\n",
            "Points: 24, Rolls Left: 15 => Action: ROLL\n",
            "Points: 17, Rolls Left: 16 => Action: ROLL\n",
            "Points: 10, Rolls Left: 17 => Action: ROLL\n",
            "Points: 8, Rolls Left: 18 => Action: ROLL\n",
            "Points: 28, Rolls Left: 17 => Action: ROLL\n",
            "Points: 10, Rolls Left: 19 => Action: ROLL\n",
            "Points: 20, Rolls Left: 16 => Action: ROLL\n",
            "Points: 12, Rolls Left: 17 => Action: ROLL\n",
            "Points: 10, Rolls Left: 18 => Action: ROLL\n",
            "Points: 29, Rolls Left: 15 => Action: ROLL\n",
            "Points: 16, Rolls Left: 18 => Action: ROLL\n",
            "Points: 24, Rolls Left: 17 => Action: ROLL\n",
            "Points: 13, Rolls Left: 17 => Action: ROLL\n",
            "Points: 25, Rolls Left: 17 => Action: ROLL\n",
            "Points: 12, Rolls Left: 19 => Action: ROLL\n",
            "Points: 27, Rolls Left: 16 => Action: ROLL\n",
            "Points: 2, Rolls Left: 19 => Action: ROLL\n",
            "Points: 21, Rolls Left: 18 => Action: ROLL\n",
            "Points: 22, Rolls Left: 17 => Action: ROLL\n",
            "Points: 7, Rolls Left: 18 => Action: ROLL\n",
            "Points: 23, Rolls Left: 15 => Action: ROLL\n",
            "Points: 17, Rolls Left: 18 => Action: ROLL\n",
            "Points: 22, Rolls Left: 16 => Action: ROLL\n",
            "Points: 29, Rolls Left: 17 => Action: ROLL\n",
            "Points: 19, Rolls Left: 16 => Action: ROLL\n",
            "Points: 29, Rolls Left: 14 => Action: ROLL\n",
            "Points: 20, Rolls Left: 18 => Action: ROLL\n",
            "Points: 22, Rolls Left: 18 => Action: ROLL\n",
            "Points: 21, Rolls Left: 15 => Action: ROLL\n",
            "Points: 5, Rolls Left: 18 => Action: ROLL\n",
            "Points: 11, Rolls Left: 17 => Action: ROLL\n",
            "Points: 19, Rolls Left: 15 => Action: ROLL\n",
            "Points: 12, Rolls Left: 16 => Action: ROLL\n",
            "Points: 27, Rolls Left: 14 => Action: ROLL\n",
            "Points: 16, Rolls Left: 16 => Action: ROLL\n",
            "Points: 24, Rolls Left: 18 => Action: ROLL\n",
            "Points: 26, Rolls Left: 14 => Action: ROLL\n",
            "Points: 22, Rolls Left: 15 => Action: ROLL\n",
            "Points: 14, Rolls Left: 16 => Action: ROLL\n",
            "Points: 8, Rolls Left: 17 => Action: ROLL\n",
            "Points: 15, Rolls Left: 16 => Action: ROLL\n",
            "Points: 23, Rolls Left: 18 => Action: ROLL\n",
            "Points: 25, Rolls Left: 14 => Action: ROLL\n",
            "Points: 9, Rolls Left: 17 => Action: ROLL\n",
            "Points: 25, Rolls Left: 13 => Action: ROLL\n",
            "Points: 23, Rolls Left: 14 => Action: ROLL\n",
            "Points: 4, Rolls Left: 18 => Action: ROLL\n",
            "Points: 20, Rolls Left: 15 => Action: ROLL\n",
            "Points: 21, Rolls Left: 14 => Action: ROLL\n",
            "Points: 15, Rolls Left: 15 => Action: ROLL\n",
            "Points: 11, Rolls Left: 16 => Action: ROLL\n",
            "Points: 24, Rolls Left: 14 => Action: ROLL\n",
            "Points: 13, Rolls Left: 16 => Action: ROLL\n",
            "Points: 17, Rolls Left: 15 => Action: ROLL\n",
            "Points: 10, Rolls Left: 16 => Action: ROLL\n",
            "Points: 18, Rolls Left: 15 => Action: ROLL\n",
            "Points: 29, Rolls Left: 12 => Action: ROLL\n",
            "Points: 22, Rolls Left: 14 => Action: ROLL\n",
            "Points: 29, Rolls Left: 13 => Action: ROLL\n",
            "Points: 28, Rolls Left: 13 => Action: ROLL\n",
            "Points: 27, Rolls Left: 13 => Action: ROLL\n",
            "Points: 26, Rolls Left: 13 => Action: ROLL\n",
            "Points: 16, Rolls Left: 15 => Action: ROLL\n",
            "Points: 7, Rolls Left: 17 => Action: ROLL\n",
            "Points: 20, Rolls Left: 14 => Action: ROLL\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "class State:\n",
        "    def __init__(self, points, rolls_left):\n",
        "        self.points = points\n",
        "        self.rolls_left = rolls_left\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'State(points={self.points}, rolls_left={self.rolls_left})'\n",
        "\n",
        "class Action:\n",
        "    ROLL = 'ROLL'\n",
        "    STOP = 'STOP'\n",
        "\n",
        "class Policy:\n",
        "    def __init__(self, policy_dict=None):\n",
        "        if policy_dict is None:\n",
        "            policy_dict = {}\n",
        "        self.policy_dict = policy_dict\n",
        "\n",
        "    def get_action(self, state):\n",
        "        return self.policy_dict.get((state.points, state.rolls_left), Action.ROLL)\n",
        "\n",
        "    def update_policy(self, state, action):\n",
        "        self.policy_dict[(state.points, state.rolls_left)] = action\n",
        "\n",
        "class Environment:\n",
        "    def __init__(self, max_rolls, reward_threshold):\n",
        "        self.max_rolls = max_rolls\n",
        "        self.reward_threshold = reward_threshold\n",
        "        self.state = None\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = State(0, self.max_rolls)\n",
        "        return self.state\n",
        "\n",
        "    def step(self, state, action):\n",
        "        if action == Action.STOP:\n",
        "            return state, 0, True\n",
        "\n",
        "        new_points = state.points + sum(random.randint(1, 6) for _ in range(2))\n",
        "        done = new_points >= self.reward_threshold or state.rolls_left <= 1\n",
        "        next_state = State(new_points, state.rolls_left - 1)\n",
        "        reward = 1 if done and new_points >= self.reward_threshold else 0\n",
        "        return next_state, reward, done\n",
        "\n",
        "def monte_carlo_learning(env, episodes=10000, gamma=0.95):\n",
        "    Q = defaultdict(lambda: {Action.ROLL: 0, Action.STOP: 0})\n",
        "    N = defaultdict(lambda: {Action.ROLL: 0, Action.STOP: 0})\n",
        "    policy = Policy()\n",
        "\n",
        "    for _ in range(episodes):\n",
        "        episode = []\n",
        "        state = env.reset()\n",
        "        while True:\n",
        "            action = policy.get_action(state)\n",
        "            next_state, reward, done = env.step(state, action)\n",
        "            episode.append((state, action, reward))\n",
        "            if done:\n",
        "                break\n",
        "            state = next_state\n",
        "\n",
        "        G = 0\n",
        "        for t in reversed(range(len(episode))):\n",
        "            state, action, reward = episode[t]\n",
        "            G = gamma * G + reward\n",
        "            N[state][action] += 1\n",
        "            Q[state][action] += (G - Q[state][action]) / N[state][action]\n",
        "            A_star = max(Q[state], key=lambda a: Q[state][a])\n",
        "            policy.update_policy(state, A_star)\n",
        "\n",
        "    return policy\n",
        "\n",
        "def main():\n",
        "    env = Environment(max_rolls=20, reward_threshold=30)\n",
        "    learned_policy = monte_carlo_learning(env)\n",
        "    print(\"Learned Policy:\")\n",
        "    for (points, rolls_left), action in learned_policy.policy_dict.items():\n",
        "        print(f\"Points: {points}, Rolls Left: {rolls_left} => Action: {action}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}
